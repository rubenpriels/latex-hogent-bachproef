%---------- Inleiding ---------------------------------------------------------

% TODO: Is dit voorstel gebaseerd op een paper van Research Methods die je
% vorig jaar hebt ingediend? Heb je daarbij eventueel samengewerkt met een
% andere student?
% Zo ja, haal dan de tekst hieronder uit commentaar en pas aan.

%\paragraph{Opmerking}

% Dit voorstel is gebaseerd op het onderzoeksvoorstel dat werd geschreven in het
% kader van het vak Research Methods dat ik (vorig/dit) academiejaar heb
% uitgewerkt (met medesturent VOORNAAM NAAM als mede-auteur).
% 

\section{Inleiding}%
\label{sec:inleiding}

Bedrijven zoals winkels en restaurants zijn sterk afhankelijk van een goede locatiekeuze. De populariteit van een locatie speelt namelijk een grote rol in het succes van een onderneming. Als een bedrijf zich vestigt op een locatie met lage bezoekersaantallen, dan leidt dit ook tot een lager klantenaantal en bijgevolg ook een lagere omzet. Talloze bedrijven hebben echter onvoldoende inzicht in de huidige en toekomstige populariteit van een locatie. Hierdoor nemen deze bedrijven verkeerde beslissingen bij nieuwe vestigingen te openen of reclamecampagnes te starten.

Dit onderzoek richt zich daarom op de hoofdvraag: “Hoe kan artificiële intelligentie worden ingezet om de populariteit van een point-of-interest te voorspellen op basis van census data?" Om deze hoofdvraag te beantwoorden, wordt het onderzoek opgedeeld in vier deelvragen. Hoe wordt de populariteit van een POI verklaard door censusdata? Welke technieken zijn er beschikbaar voor dataverzameling? Welke deep learning-modellen zijn geschikt om POI-populariteit te voorspellen? Welke technieken bestaan er om de prestaties van zulke deep learning-modellen te verbeteren? De gewenste oplossing moet bedrijven in staat stellen om op basis van de voorspellingen een strategische locatie te kiezen voor een vestiging te openen of een marketingcampagne te starten. De oplossing moet dus technisch haalbaar zijn en een foutmarge van maximaal 10\% hebben voor voorspellingen binnen 1 jaar.

\bigskip
%---------- Stand van zaken ---------------------------------------------------

\section{Literatuurstudie}
\label{sec:literatuurstudie}

Deze literatuurstudie analyseert welke deep learning-modellen geschikt zijn voor het voorspellen van de populariteit van POI's op basis van censusdata. De studie legt de nadruk op drie verschillende deep learning modellen, namelijk multi-layer perceptrons (MLP), recurrent neural networks (RNN) en transformers. Daarnaast wordt er besproken hoe synthetische data kan worden ingezet om data schaarste tegen te gaan. Tot slot wordt er nagegaan welke hyperparameter tuning technieken bestaan om deep learning modellen te optimaliseren.

\subsection{POI-populariteit en censusdata}
De populariteit van een POI kan verklaard worden aan de hand van censusdata. \textcite{Juhasz2020} tonen aan dat de bevolkingsdichtheid een belangrijke rol speelt. Hoe hoger de bevolkingsdichtheid is, hoe groter de kans dat mensen langs een bepaalde locatie komen. Daarnaast is de werkgelegenheidsdichtheid ook een cruciale factor bij het aantal bezoekers van een POI. Locaties waar de werkgelegenheidsdichtheid hoog ligt, zijn vaak gebieden waar mensen naartoe moeten voor hun werk. Het aantal bezoekers zal dus ook hoger liggen aangezien zowel mensen die binnen als buiten de stad wonen naar hun werk moeten pendelen.

\subsection{Deep learning-modellen}
Allereerst is het relevant om drie geschikte modellen te vergelijken, namelijk Multi-Layer Perceptron (MLP), Recurrent Neural Network (RNN) en transformers. Deze drie modellen gebruiken verschillende methodes om de doelvariabele te voorspellen waarbij ze elk hun voor- en nadelen hebben.

Het eerste model dat wordt besproken is MLP. Volgens onderzoek \autocite{Duan2025} is MLP eenvoudiger te ontwikkelen dan modellen zoals RNN en transformers. Daarnaast presteert MLP vaak beter wanneer er een beperkte dataset beschikbaar is. Een belangrijk nadeel aan MLP is dat het geen ingebouwde manier heeft om verbanden doorheen de tijd vast te stellen \autocite{Kim2025}. MLP behandelt elke input als een afzonderlijk punt in de data in plaats van een volgend punt in een tijdreeks.

Aan de andere kant vertelt \textcite{Song2024} dat RNN wel rekening houdt met tijdsafhankelijke verbanden. RNN gebruikt namelijk elke output die het genereert als input voor de volgende stap. Zo kan het model eerdere informatie onthouden en trends in tijdreeksen modelleren. Het grote nadeel aan RNN is dat het slecht is om lange afstandsrelaties te ontdekken. Trends in de censusdata die zich over lange tijdsperiodes ontwikkelen worden dus mogelijk niet ontdekt door het RNN. 

Tot slot bestaan er ook transformers. Volgens \textcite{Vaswani2017} maken transformers gebruik van self-attention om verbanden over een hele tijdreeks tegelijk te analyseren. Hierdoor kunnen ze zowel korte- als langetermijnrelaties nauwkeurig vaststellen. Bovendien maken transformers gebruik van parallellisme waardoor ze grote hoeveelheden data efficiënt kunnen verwerken. Het grote probleem met transformers is dat ze complex zijn en grote hoeveelheden data nodig hebben om goed te presteren. Dit kan een probleem vormen aangezien de accuraatheid van de transformer sterk daalt als er niet voldoende data is om het model mee te trainen.

\subsection{Dataverzameling}
Naast de keuze van een deep learning model speelt dus ook de hoeveelheid en diversiteit van de dataset een belangrijke rol. Om de populariteit van POI's zo nauwkeurig mogelijk te kunnen voorspellen, is een grote hoeveelheid censusdata nodig. Volgens \textcite{Hestness2017} zorgen grote hoeveelheden diverse data voor betere generalisatie wat de precisie van deep learning-modellen verbetert. Daarom is het essentieel dat het deep learning-model voldoende data ontvangt om de populariteit van een POI zo nauwkeurig mogelijk te voorspellen.

\subsection{Synthetische data}
Er kan gebruikgemaakt worden van synthetische data in plaats van echte data. Zoals door \textcite{Dankar2021} wordt gedefinieerd is synthetische data kunstmatig gegenereerde data gebaseerd op echte gegevens, zoals gebeurtenissen, personen of objecten. Een model genereert deze data door de eigenschappen en structuur van de oorspronkelijke dataset na te bootsen. Deze techniek wordt toegepast met persoonlijke gegevens zoals medische records, om privacy te beschermen. Door synthetische data in te zetten, ontstaan er verschillende voordelen. Volgens onderzoek \autocite{Ghorbani2019} kan synthetische data worden ingezet wanneer er onvoldoende data beschikbaar is om een AI-model mee te trainen. Daarnaast kan het uitstekend randgevallen simuleren. Synthetische data lost dus niet alleen data schaarste op, maar maakt het ook mogelijk om randgevallen goed te bestuderen. Hierdoor verbeteren de prestaties van de deep learning-modellen.

\subsection{Hyperparameter tuning}
Een standaard deep learning-model is vaak niet voldoende om de populariteit van een POI nauwkeurig te kunnen voorspellen. Hoe kleiner de voorspellingsfouten zijn, hoe gerichter een onderneming een locatie voor hun marktactiviteiten kan kiezen. Om de prestaties van een model te optimaliseren, kunnen verschillende optimalisatietechnieken worden toegepast.

Volgens \textcite{Yang2020} spelen hyperparameters een belangrijke rol bij deep learning-modellen. Hyperparameters zijn namelijk parameters die voor het trainen van een model ingesteld worden. De prestaties van het model hangen af van de gekozen hyperparameters. Het probleem is echter dat er geen manier is om op voorhand te bepalen welke hyperparameter combinatie het beste werkt. Hierdoor moeten er verschillende combinaties uitgetest worden wat veel tijd kost.

Om dit probleem op te lossen, kan er een methode genaamd hyperparameter tuning ingezet worden. Hierbij worden meerdere waarden tegelijk meegegeven aan het model. Het model probeert dan verschillende hyperparameter combinaties uit. Op het einde van het trainen behoudt het model de hyperparameter combinatie die het beste presteert op de dataset. Zo verhoogt de accuraatheid van het model significant.

\subsection{Hyperparameter tuning technieken}
Er zullen twee geschikte hyperparameter tuning technieken vergeleken worden, namelijk ra-
ndom search en bayesian optimization. Volgens \textcite{Kee2025} zijn random search en bayesian optimization twee veelgebruikte methoden om de beste hyperparameter combinatie te vinden. Random search is een eenvoudige methode die willekeurige combinaties van hyperparameters uitprobeert. Een groot voordeel van random search is dat het eenvoudig te gebruiken en snel te implementeren is. Daarnaast presteert random search goed wanneer er veel hyperparameter waarden zijn zonder dat het complexe algoritmes moet gebruiken.

Verder kan ook bayesian optimization gebruikt worden. Deze methode analyseert de prestaties van eerdere hyperparameter combinaties zodat het voor volgende runs gerichter combinaties kan uitproberen. De methode weet dus op basis van eerdere resultaten welke hyperparameter combinaties waarschijnlijk goed zullen presenteren. Hierdoor kan bayesian optimization met minder runs goede hyperparameter combinaties vinden aangezien het van eerdere resultaten leert.

\subsection{Conclusie}
Kortom, het literatuuronderzoek suggereert dat modellen zoals MLP, RNN en transformers geschikt zijn om de populariteit van  POI's te voorspellen op basis van censusdata. MLP zal worden ingezet voor simpliciteit en wanneer de dataset beperkt is, terwijl RNN gebruikt zal worden als tijdsafhankelijke verbanden ontdekken belangrijk is. Tot slot kunnen transformers ingezet worden als complexiteit niet belangrijk is en er een grote dataset beschikbaar is. Daarnaast worden finetuning technieken zoals random search en bayesian optimization gebruikt om de resultaten van deep learning modellen te optimaliseren.

% Voor literatuurverwijzingen zijn er twee belangrijke commando's:
% \autocite{KEY} => (Auteur, jaartal) Gebruik dit als de naam van de auteur
%   geen onderdeel is van de zin.
% \textcite{KEY} => Auteur (jaartal)  Gebruik dit als de auteursnaam wel een
%   functie heeft in de zin (bv. ``Uit onderzoek door Doll & Hill (1954) bleek
%   ...'')

\clearpage
%---------- Methodologie ------------------------------------------------------
\section{Methodologie}%
\label{sec:methodologie}

\paragraph{Fase 1: Literatuurstudie.}
Het doel van de eerste fase is om een inzicht te krijgen in bestaande deep learning-modellen en technieken voor dataverzameling en model optimalisatie. Daarnaast worden de specifieke voorwaarden opgesteld van het deep learning-model dat voldaan moet zijn om de oplossing als een succes te beschouwen. Hiervoor wordt een literatuuronderzoek uitgevo-
erd naar verschillende onderzoekspapers om geschikte deep learning-modellen te identificeren zoals MLP die tot een mogelijke oplossing kunnen leiden. Deze papers behandelen zowel real-world use cases waar deze modellen gebruikt worden als reviews over de architectuur van specifieke modellen zoals transformers. Aan het einde van deze fase is een uitgebreide documentatie van mogelijke deep learning-modellen en technieken voor dataverzameling en model optimalisatie opgesteld. Daarnaast is de maximale voorspellingsfout en model nauwkeurigheid duidelijk afgebakend. De maximale voorspellingsfout geeft aan hoeveel de voorspellingen maximaal mogen afwijken van de werkelijke waarden en het model nauwkeurigheid geeft aan hoe goed het model de variatie in de data verklaart. De literatuurstudie vindt plaats twee dagen per week over een periode van zeven weken. Er wordt verwacht dat deze deliverables afgewerkt zijn op 23 maart.

\paragraph{Fase 2: Data verzamelen.}
Het doel van de twe-
ede fase is om voldoende diverse data te verzamelen om de deep learning-modellen mee te trainen in de volgende fase. Hierbij worden zowel openbare datasets als door bedrijf aangeleverde datasets gebruikt. Daarnaast worden technieken uit de eerste fase toegepast om data schaarste tegen te gaan zoals synthetische data. Aan het einde van deze fase is er een dataset beschikbaar van censusdata waarmee de deep learning-modellen uit de volgende fase mee getraind kunnen worden. Deze fase vindt plaats twee dagen per week over een periode van vijf weken. Er wordt verwacht dat deze deliverables afgewerkt zijn op 6 april.

\paragraph{Fase 3: deep learning-model implementatie.}
Het doel van de derde fase is om deep learning-modellen te implementeren op basis van de bevindingen uit de literatuurstudie. Deze modellen kunnen op basis van censusdata de populariteit van een POI voorspellen. Eerst worden de standaard deep learning-modellen geprogrammeerd die in fase 1 zijn onderzocht. Vervolgens worden deze modellen geoptimaliseerd door de in de literatuurstudie beschreven technieken voor model optimalisatie toe te passen. Deze deep learning-modellen worden getraind op de dataset uit de vorige fase. Aan het einde van deze fase zijn werkende deep learning-modellen ontwikkeld op basis van de literatuurstudie. Deze kunnen de populariteit van een POI voorspellen. De implementatie van de deep learning-modellen vindt plaats twee dagen per week over een periode van vijf weken. Er wordt verwacht dat deze deliverables afgewerkt zijn op 13 april.

\paragraph{Fase 4: Experimenten uitvoeren.}
Het doel van de vierde fase is om de deep learning-modellen te testen door middel van experimenten. Alle deep learning-modellen die zijn ontwikkeld tijdens de Proof of Concept zullen dezelfde experimenten ondergaan. Ze worden geëvalueerd aan de hand van verschillende prestatiemaatstaven waaronder RMSE, MAE en R². De experimenten omvatten voorspellingen op diverse scenario's zoals reguliere gevallen, situaties met beperkte data, tijdsperiodes met evenementen op een specifieke locatie en feestdagen. Aan het einde van deze fase is elk deep learning-model geëvalueerd, wat resulteert in een gedetailleerd rapport van hun prestaties. Deze experimenten vinden plaats twee dagen per week over een periode van vier weken. Er wordt verwacht dat deze deliverables afgewerkt zijn op 27 april.

\paragraph{Fase 5: Evaluatie van deep learning-modellen.}
In de laatste fase worden de prestaties van de verschillende deep learning-modellen geëvalueerd voor gebruik in real world cases waarbij bedrijven een locatie kunnen kiezen aan de hand van deze voorspellingen. De resultaten uit de vorige fase worden zowel individueel geanalyseerd als vergeleken met de resultaten van de andere deep learning-modellen. Hierdoor wordt nagegaan welke modellen beter zijn in specifieke situaties, maar ook welk model in het algemeen het beste presteert op de vooraf gedefinieerde criteria. De deliverables van deze fase is een uitgebreide rapportage waarin alle deep learning-modellen worden geanalyseerd op basis van de vooraf gedefinieerde criteria en hoe ze presteren ten opzichte van andere modellen. Hieruit wordt geconcludeerd welk deep learning-model het meest geschikt is om de populariteit van POI's te voorspellen en of deze daadwerkelijk voldoet aan de vereisten die in fase 1 werden vastgelegd. Tot slot worden mogelijke beperkingen gedocumenteerd zoals slechtere prestaties bij uitzonderlijke situaties samen met aanbevelingen voor verbeteringen. De evaluatie van de deep learning-modellen vindt plaats twee dagen per week over een periode van drie weken. Er wordt verwacht dat deze deliverables afgewerkt zijn op 18 mei.

\begin{figure*}
  \centering
  \includegraphics[width=\textwidth]{img/Gantt_diagram.png}
  \caption{\label{fig:gantt}Gantt diagram met de verschillende fasen en milestones van de bachelorproef.}
\end{figure*}

%---------- Verwachte resultaten ----------------------------------------------
\section{Verwacht resultaat, conclusie}%
\label{sec:verwachte_resultaten}

Volgens de literatuurstudie is de populariteit van een POI voorspellen mogelijk met behulp van bestaande deep learning-modellen zoals MLP, RNN en transformers. Elk model heeft specifieke voor- en nadelen. MLP is eenvoudig te implementeren en geschikt voor kleine datasets, maar het heeft moeite met tijdsafhankelijke verbanden leggen. Daarnaast kan RNN wel tijdsafhankelijke verbanden leggen, maar worstelt met lange afstandsrelaties. Transformers kunnen zowel korte als lange afstandsrelaties efficiënt ontdekken, maar ze zijn complex en hebben grote hoeveelheden data nodig.

Omdat de prestaties van deze modellen sterk afhankelijk zijn van de beschikbare data, kan een gebrek aan voldoende diverse censusdata een uitdaging vormen. Dit zou echter opgelost moeten raken door technieken voor dataverzameling toe te passen zoals synthetische data.

Tot slot worden de modellen geoptimaliseerd door de beste hyperparameter combinatie van elk model te vinden met behulp van random search en bayesian optimization. Hierdoor zullen de deep learning-modellen beter presteren op nieuwe data.

Deze verwachte resultaten hebben invloed op verschillende aspecten van de bedrijfswereld. Door de populariteit van een locatie te voorspellen kunnen bedrijven strategische beslissingen nemen bij een vestiging te openen of een reclamecampagne te starten. Hierdoor zullen ondernemingen meer omzet kunnen maken en startende bedrijven zullen een grotere kans hebben om te overleven.
